{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Breast Cancer Prediction"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I will be using the Breast Cancer Wisconsin (Diagnostic) Database to create a classifier that can help diagnose patients. First, read through the description of the dataset (below)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ".. _breast_cancer_dataset:\n",
      "\n",
      "Breast cancer wisconsin (diagnostic) dataset\n",
      "--------------------------------------------\n",
      "\n",
      "**Data Set Characteristics:**\n",
      "\n",
      "    :Number of Instances: 569\n",
      "\n",
      "    :Number of Attributes: 30 numeric, predictive attributes and the class\n",
      "\n",
      "    :Attribute Information:\n",
      "        - radius (mean of distances from center to points on the perimeter)\n",
      "        - texture (standard deviation of gray-scale values)\n",
      "        - perimeter\n",
      "        - area\n",
      "        - smoothness (local variation in radius lengths)\n",
      "        - compactness (perimeter^2 / area - 1.0)\n",
      "        - concavity (severity of concave portions of the contour)\n",
      "        - concave points (number of concave portions of the contour)\n",
      "        - symmetry \n",
      "        - fractal dimension (\"coastline approximation\" - 1)\n",
      "\n",
      "        The mean, standard error, and \"worst\" or largest (mean of the three\n",
      "        largest values) of these features were computed for each image,\n",
      "        resulting in 30 features.  For instance, field 3 is Mean Radius, field\n",
      "        13 is Radius SE, field 23 is Worst Radius.\n",
      "\n",
      "        - class:\n",
      "                - WDBC-Malignant\n",
      "                - WDBC-Benign\n",
      "\n",
      "    :Summary Statistics:\n",
      "\n",
      "    ===================================== ====== ======\n",
      "                                           Min    Max\n",
      "    ===================================== ====== ======\n",
      "    radius (mean):                        6.981  28.11\n",
      "    texture (mean):                       9.71   39.28\n",
      "    perimeter (mean):                     43.79  188.5\n",
      "    area (mean):                          143.5  2501.0\n",
      "    smoothness (mean):                    0.053  0.163\n",
      "    compactness (mean):                   0.019  0.345\n",
      "    concavity (mean):                     0.0    0.427\n",
      "    concave points (mean):                0.0    0.201\n",
      "    symmetry (mean):                      0.106  0.304\n",
      "    fractal dimension (mean):             0.05   0.097\n",
      "    radius (standard error):              0.112  2.873\n",
      "    texture (standard error):             0.36   4.885\n",
      "    perimeter (standard error):           0.757  21.98\n",
      "    area (standard error):                6.802  542.2\n",
      "    smoothness (standard error):          0.002  0.031\n",
      "    compactness (standard error):         0.002  0.135\n",
      "    concavity (standard error):           0.0    0.396\n",
      "    concave points (standard error):      0.0    0.053\n",
      "    symmetry (standard error):            0.008  0.079\n",
      "    fractal dimension (standard error):   0.001  0.03\n",
      "    radius (worst):                       7.93   36.04\n",
      "    texture (worst):                      12.02  49.54\n",
      "    perimeter (worst):                    50.41  251.2\n",
      "    area (worst):                         185.2  4254.0\n",
      "    smoothness (worst):                   0.071  0.223\n",
      "    compactness (worst):                  0.027  1.058\n",
      "    concavity (worst):                    0.0    1.252\n",
      "    concave points (worst):               0.0    0.291\n",
      "    symmetry (worst):                     0.156  0.664\n",
      "    fractal dimension (worst):            0.055  0.208\n",
      "    ===================================== ====== ======\n",
      "\n",
      "    :Missing Attribute Values: None\n",
      "\n",
      "    :Class Distribution: 212 - Malignant, 357 - Benign\n",
      "\n",
      "    :Creator:  Dr. William H. Wolberg, W. Nick Street, Olvi L. Mangasarian\n",
      "\n",
      "    :Donor: Nick Street\n",
      "\n",
      "    :Date: November, 1995\n",
      "\n",
      "This is a copy of UCI ML Breast Cancer Wisconsin (Diagnostic) datasets.\n",
      "https://goo.gl/U2Uwz2\n",
      "\n",
      "Features are computed from a digitized image of a fine needle\n",
      "aspirate (FNA) of a breast mass.  They describe\n",
      "characteristics of the cell nuclei present in the image.\n",
      "\n",
      "Separating plane described above was obtained using\n",
      "Multisurface Method-Tree (MSM-T) [K. P. Bennett, \"Decision Tree\n",
      "Construction Via Linear Programming.\" Proceedings of the 4th\n",
      "Midwest Artificial Intelligence and Cognitive Science Society,\n",
      "pp. 97-101, 1992], a classification method which uses linear\n",
      "programming to construct a decision tree.  Relevant features\n",
      "were selected using an exhaustive search in the space of 1-4\n",
      "features and 1-3 separating planes.\n",
      "\n",
      "The actual linear program used to obtain the separating plane\n",
      "in the 3-dimensional space is that described in:\n",
      "[K. P. Bennett and O. L. Mangasarian: \"Robust Linear\n",
      "Programming Discrimination of Two Linearly Inseparable Sets\",\n",
      "Optimization Methods and Software 1, 1992, 23-34].\n",
      "\n",
      "This database is also available through the UW CS ftp server:\n",
      "\n",
      "ftp ftp.cs.wisc.edu\n",
      "cd math-prog/cpo-dataset/machine-learn/WDBC/\n",
      "\n",
      ".. topic:: References\n",
      "\n",
      "   - W.N. Street, W.H. Wolberg and O.L. Mangasarian. Nuclear feature extraction \n",
      "     for breast tumor diagnosis. IS&T/SPIE 1993 International Symposium on \n",
      "     Electronic Imaging: Science and Technology, volume 1905, pages 861-870,\n",
      "     San Jose, CA, 1993.\n",
      "   - O.L. Mangasarian, W.N. Street and W.H. Wolberg. Breast cancer diagnosis and \n",
      "     prognosis via linear programming. Operations Research, 43(4), pages 570-577, \n",
      "     July-August 1995.\n",
      "   - W.H. Wolberg, W.N. Street, and O.L. Mangasarian. Machine learning techniques\n",
      "     to diagnose breast cancer from fine-needle aspirates. Cancer Letters 77 (1994) \n",
      "     163-171.\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.datasets import load_breast_cancer\n",
    "\n",
    "cancer = load_breast_cancer()\n",
    "\n",
    "print(cancer.DESCR) # Print the data set description"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The object returned by `load_breast_cancer()` is a scikit-learn Bunch object, which is similar to a dictionary."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['data', 'target', 'target_names', 'DESCR', 'feature_names', 'filename'])"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cancer.keys()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### How many features does the breast cancer dataset have?\n",
    "\n",
    "*This function returns an integer.*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "30"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(cancer['feature_names'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>mean radius</th>\n",
       "      <th>mean texture</th>\n",
       "      <th>mean perimeter</th>\n",
       "      <th>mean area</th>\n",
       "      <th>mean smoothness</th>\n",
       "      <th>mean compactness</th>\n",
       "      <th>mean concavity</th>\n",
       "      <th>mean concave points</th>\n",
       "      <th>mean symmetry</th>\n",
       "      <th>mean fractal dimension</th>\n",
       "      <th>...</th>\n",
       "      <th>worst texture</th>\n",
       "      <th>worst perimeter</th>\n",
       "      <th>worst area</th>\n",
       "      <th>worst smoothness</th>\n",
       "      <th>worst compactness</th>\n",
       "      <th>worst concavity</th>\n",
       "      <th>worst concave points</th>\n",
       "      <th>worst symmetry</th>\n",
       "      <th>worst fractal dimension</th>\n",
       "      <th>target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>17.99</td>\n",
       "      <td>10.38</td>\n",
       "      <td>122.80</td>\n",
       "      <td>1001.0</td>\n",
       "      <td>0.11840</td>\n",
       "      <td>0.27760</td>\n",
       "      <td>0.30010</td>\n",
       "      <td>0.14710</td>\n",
       "      <td>0.2419</td>\n",
       "      <td>0.07871</td>\n",
       "      <td>...</td>\n",
       "      <td>17.33</td>\n",
       "      <td>184.60</td>\n",
       "      <td>2019.0</td>\n",
       "      <td>0.1622</td>\n",
       "      <td>0.6656</td>\n",
       "      <td>0.7119</td>\n",
       "      <td>0.26540</td>\n",
       "      <td>0.4601</td>\n",
       "      <td>0.11890</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>20.57</td>\n",
       "      <td>17.77</td>\n",
       "      <td>132.90</td>\n",
       "      <td>1326.0</td>\n",
       "      <td>0.08474</td>\n",
       "      <td>0.07864</td>\n",
       "      <td>0.08690</td>\n",
       "      <td>0.07017</td>\n",
       "      <td>0.1812</td>\n",
       "      <td>0.05667</td>\n",
       "      <td>...</td>\n",
       "      <td>23.41</td>\n",
       "      <td>158.80</td>\n",
       "      <td>1956.0</td>\n",
       "      <td>0.1238</td>\n",
       "      <td>0.1866</td>\n",
       "      <td>0.2416</td>\n",
       "      <td>0.18600</td>\n",
       "      <td>0.2750</td>\n",
       "      <td>0.08902</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>19.69</td>\n",
       "      <td>21.25</td>\n",
       "      <td>130.00</td>\n",
       "      <td>1203.0</td>\n",
       "      <td>0.10960</td>\n",
       "      <td>0.15990</td>\n",
       "      <td>0.19740</td>\n",
       "      <td>0.12790</td>\n",
       "      <td>0.2069</td>\n",
       "      <td>0.05999</td>\n",
       "      <td>...</td>\n",
       "      <td>25.53</td>\n",
       "      <td>152.50</td>\n",
       "      <td>1709.0</td>\n",
       "      <td>0.1444</td>\n",
       "      <td>0.4245</td>\n",
       "      <td>0.4504</td>\n",
       "      <td>0.24300</td>\n",
       "      <td>0.3613</td>\n",
       "      <td>0.08758</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>11.42</td>\n",
       "      <td>20.38</td>\n",
       "      <td>77.58</td>\n",
       "      <td>386.1</td>\n",
       "      <td>0.14250</td>\n",
       "      <td>0.28390</td>\n",
       "      <td>0.24140</td>\n",
       "      <td>0.10520</td>\n",
       "      <td>0.2597</td>\n",
       "      <td>0.09744</td>\n",
       "      <td>...</td>\n",
       "      <td>26.50</td>\n",
       "      <td>98.87</td>\n",
       "      <td>567.7</td>\n",
       "      <td>0.2098</td>\n",
       "      <td>0.8663</td>\n",
       "      <td>0.6869</td>\n",
       "      <td>0.25750</td>\n",
       "      <td>0.6638</td>\n",
       "      <td>0.17300</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>20.29</td>\n",
       "      <td>14.34</td>\n",
       "      <td>135.10</td>\n",
       "      <td>1297.0</td>\n",
       "      <td>0.10030</td>\n",
       "      <td>0.13280</td>\n",
       "      <td>0.19800</td>\n",
       "      <td>0.10430</td>\n",
       "      <td>0.1809</td>\n",
       "      <td>0.05883</td>\n",
       "      <td>...</td>\n",
       "      <td>16.67</td>\n",
       "      <td>152.20</td>\n",
       "      <td>1575.0</td>\n",
       "      <td>0.1374</td>\n",
       "      <td>0.2050</td>\n",
       "      <td>0.4000</td>\n",
       "      <td>0.16250</td>\n",
       "      <td>0.2364</td>\n",
       "      <td>0.07678</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>12.45</td>\n",
       "      <td>15.70</td>\n",
       "      <td>82.57</td>\n",
       "      <td>477.1</td>\n",
       "      <td>0.12780</td>\n",
       "      <td>0.17000</td>\n",
       "      <td>0.15780</td>\n",
       "      <td>0.08089</td>\n",
       "      <td>0.2087</td>\n",
       "      <td>0.07613</td>\n",
       "      <td>...</td>\n",
       "      <td>23.75</td>\n",
       "      <td>103.40</td>\n",
       "      <td>741.6</td>\n",
       "      <td>0.1791</td>\n",
       "      <td>0.5249</td>\n",
       "      <td>0.5355</td>\n",
       "      <td>0.17410</td>\n",
       "      <td>0.3985</td>\n",
       "      <td>0.12440</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>18.25</td>\n",
       "      <td>19.98</td>\n",
       "      <td>119.60</td>\n",
       "      <td>1040.0</td>\n",
       "      <td>0.09463</td>\n",
       "      <td>0.10900</td>\n",
       "      <td>0.11270</td>\n",
       "      <td>0.07400</td>\n",
       "      <td>0.1794</td>\n",
       "      <td>0.05742</td>\n",
       "      <td>...</td>\n",
       "      <td>27.66</td>\n",
       "      <td>153.20</td>\n",
       "      <td>1606.0</td>\n",
       "      <td>0.1442</td>\n",
       "      <td>0.2576</td>\n",
       "      <td>0.3784</td>\n",
       "      <td>0.19320</td>\n",
       "      <td>0.3063</td>\n",
       "      <td>0.08368</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>13.71</td>\n",
       "      <td>20.83</td>\n",
       "      <td>90.20</td>\n",
       "      <td>577.9</td>\n",
       "      <td>0.11890</td>\n",
       "      <td>0.16450</td>\n",
       "      <td>0.09366</td>\n",
       "      <td>0.05985</td>\n",
       "      <td>0.2196</td>\n",
       "      <td>0.07451</td>\n",
       "      <td>...</td>\n",
       "      <td>28.14</td>\n",
       "      <td>110.60</td>\n",
       "      <td>897.0</td>\n",
       "      <td>0.1654</td>\n",
       "      <td>0.3682</td>\n",
       "      <td>0.2678</td>\n",
       "      <td>0.15560</td>\n",
       "      <td>0.3196</td>\n",
       "      <td>0.11510</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>13.00</td>\n",
       "      <td>21.82</td>\n",
       "      <td>87.50</td>\n",
       "      <td>519.8</td>\n",
       "      <td>0.12730</td>\n",
       "      <td>0.19320</td>\n",
       "      <td>0.18590</td>\n",
       "      <td>0.09353</td>\n",
       "      <td>0.2350</td>\n",
       "      <td>0.07389</td>\n",
       "      <td>...</td>\n",
       "      <td>30.73</td>\n",
       "      <td>106.20</td>\n",
       "      <td>739.3</td>\n",
       "      <td>0.1703</td>\n",
       "      <td>0.5401</td>\n",
       "      <td>0.5390</td>\n",
       "      <td>0.20600</td>\n",
       "      <td>0.4378</td>\n",
       "      <td>0.10720</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>12.46</td>\n",
       "      <td>24.04</td>\n",
       "      <td>83.97</td>\n",
       "      <td>475.9</td>\n",
       "      <td>0.11860</td>\n",
       "      <td>0.23960</td>\n",
       "      <td>0.22730</td>\n",
       "      <td>0.08543</td>\n",
       "      <td>0.2030</td>\n",
       "      <td>0.08243</td>\n",
       "      <td>...</td>\n",
       "      <td>40.68</td>\n",
       "      <td>97.65</td>\n",
       "      <td>711.4</td>\n",
       "      <td>0.1853</td>\n",
       "      <td>1.0580</td>\n",
       "      <td>1.1050</td>\n",
       "      <td>0.22100</td>\n",
       "      <td>0.4366</td>\n",
       "      <td>0.20750</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>16.02</td>\n",
       "      <td>23.24</td>\n",
       "      <td>102.70</td>\n",
       "      <td>797.8</td>\n",
       "      <td>0.08206</td>\n",
       "      <td>0.06669</td>\n",
       "      <td>0.03299</td>\n",
       "      <td>0.03323</td>\n",
       "      <td>0.1528</td>\n",
       "      <td>0.05697</td>\n",
       "      <td>...</td>\n",
       "      <td>33.88</td>\n",
       "      <td>123.80</td>\n",
       "      <td>1150.0</td>\n",
       "      <td>0.1181</td>\n",
       "      <td>0.1551</td>\n",
       "      <td>0.1459</td>\n",
       "      <td>0.09975</td>\n",
       "      <td>0.2948</td>\n",
       "      <td>0.08452</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>15.78</td>\n",
       "      <td>17.89</td>\n",
       "      <td>103.60</td>\n",
       "      <td>781.0</td>\n",
       "      <td>0.09710</td>\n",
       "      <td>0.12920</td>\n",
       "      <td>0.09954</td>\n",
       "      <td>0.06606</td>\n",
       "      <td>0.1842</td>\n",
       "      <td>0.06082</td>\n",
       "      <td>...</td>\n",
       "      <td>27.28</td>\n",
       "      <td>136.50</td>\n",
       "      <td>1299.0</td>\n",
       "      <td>0.1396</td>\n",
       "      <td>0.5609</td>\n",
       "      <td>0.3965</td>\n",
       "      <td>0.18100</td>\n",
       "      <td>0.3792</td>\n",
       "      <td>0.10480</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>19.17</td>\n",
       "      <td>24.80</td>\n",
       "      <td>132.40</td>\n",
       "      <td>1123.0</td>\n",
       "      <td>0.09740</td>\n",
       "      <td>0.24580</td>\n",
       "      <td>0.20650</td>\n",
       "      <td>0.11180</td>\n",
       "      <td>0.2397</td>\n",
       "      <td>0.07800</td>\n",
       "      <td>...</td>\n",
       "      <td>29.94</td>\n",
       "      <td>151.70</td>\n",
       "      <td>1332.0</td>\n",
       "      <td>0.1037</td>\n",
       "      <td>0.3903</td>\n",
       "      <td>0.3639</td>\n",
       "      <td>0.17670</td>\n",
       "      <td>0.3176</td>\n",
       "      <td>0.10230</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>15.85</td>\n",
       "      <td>23.95</td>\n",
       "      <td>103.70</td>\n",
       "      <td>782.7</td>\n",
       "      <td>0.08401</td>\n",
       "      <td>0.10020</td>\n",
       "      <td>0.09938</td>\n",
       "      <td>0.05364</td>\n",
       "      <td>0.1847</td>\n",
       "      <td>0.05338</td>\n",
       "      <td>...</td>\n",
       "      <td>27.66</td>\n",
       "      <td>112.00</td>\n",
       "      <td>876.5</td>\n",
       "      <td>0.1131</td>\n",
       "      <td>0.1924</td>\n",
       "      <td>0.2322</td>\n",
       "      <td>0.11190</td>\n",
       "      <td>0.2809</td>\n",
       "      <td>0.06287</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>13.73</td>\n",
       "      <td>22.61</td>\n",
       "      <td>93.60</td>\n",
       "      <td>578.3</td>\n",
       "      <td>0.11310</td>\n",
       "      <td>0.22930</td>\n",
       "      <td>0.21280</td>\n",
       "      <td>0.08025</td>\n",
       "      <td>0.2069</td>\n",
       "      <td>0.07682</td>\n",
       "      <td>...</td>\n",
       "      <td>32.01</td>\n",
       "      <td>108.80</td>\n",
       "      <td>697.7</td>\n",
       "      <td>0.1651</td>\n",
       "      <td>0.7725</td>\n",
       "      <td>0.6943</td>\n",
       "      <td>0.22080</td>\n",
       "      <td>0.3596</td>\n",
       "      <td>0.14310</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>14.54</td>\n",
       "      <td>27.54</td>\n",
       "      <td>96.73</td>\n",
       "      <td>658.8</td>\n",
       "      <td>0.11390</td>\n",
       "      <td>0.15950</td>\n",
       "      <td>0.16390</td>\n",
       "      <td>0.07364</td>\n",
       "      <td>0.2303</td>\n",
       "      <td>0.07077</td>\n",
       "      <td>...</td>\n",
       "      <td>37.13</td>\n",
       "      <td>124.10</td>\n",
       "      <td>943.2</td>\n",
       "      <td>0.1678</td>\n",
       "      <td>0.6577</td>\n",
       "      <td>0.7026</td>\n",
       "      <td>0.17120</td>\n",
       "      <td>0.4218</td>\n",
       "      <td>0.13410</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>14.68</td>\n",
       "      <td>20.13</td>\n",
       "      <td>94.74</td>\n",
       "      <td>684.5</td>\n",
       "      <td>0.09867</td>\n",
       "      <td>0.07200</td>\n",
       "      <td>0.07395</td>\n",
       "      <td>0.05259</td>\n",
       "      <td>0.1586</td>\n",
       "      <td>0.05922</td>\n",
       "      <td>...</td>\n",
       "      <td>30.88</td>\n",
       "      <td>123.40</td>\n",
       "      <td>1138.0</td>\n",
       "      <td>0.1464</td>\n",
       "      <td>0.1871</td>\n",
       "      <td>0.2914</td>\n",
       "      <td>0.16090</td>\n",
       "      <td>0.3029</td>\n",
       "      <td>0.08216</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>16.13</td>\n",
       "      <td>20.68</td>\n",
       "      <td>108.10</td>\n",
       "      <td>798.8</td>\n",
       "      <td>0.11700</td>\n",
       "      <td>0.20220</td>\n",
       "      <td>0.17220</td>\n",
       "      <td>0.10280</td>\n",
       "      <td>0.2164</td>\n",
       "      <td>0.07356</td>\n",
       "      <td>...</td>\n",
       "      <td>31.48</td>\n",
       "      <td>136.80</td>\n",
       "      <td>1315.0</td>\n",
       "      <td>0.1789</td>\n",
       "      <td>0.4233</td>\n",
       "      <td>0.4784</td>\n",
       "      <td>0.20730</td>\n",
       "      <td>0.3706</td>\n",
       "      <td>0.11420</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>19.81</td>\n",
       "      <td>22.15</td>\n",
       "      <td>130.00</td>\n",
       "      <td>1260.0</td>\n",
       "      <td>0.09831</td>\n",
       "      <td>0.10270</td>\n",
       "      <td>0.14790</td>\n",
       "      <td>0.09498</td>\n",
       "      <td>0.1582</td>\n",
       "      <td>0.05395</td>\n",
       "      <td>...</td>\n",
       "      <td>30.88</td>\n",
       "      <td>186.80</td>\n",
       "      <td>2398.0</td>\n",
       "      <td>0.1512</td>\n",
       "      <td>0.3150</td>\n",
       "      <td>0.5372</td>\n",
       "      <td>0.23880</td>\n",
       "      <td>0.2768</td>\n",
       "      <td>0.07615</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>13.54</td>\n",
       "      <td>14.36</td>\n",
       "      <td>87.46</td>\n",
       "      <td>566.3</td>\n",
       "      <td>0.09779</td>\n",
       "      <td>0.08129</td>\n",
       "      <td>0.06664</td>\n",
       "      <td>0.04781</td>\n",
       "      <td>0.1885</td>\n",
       "      <td>0.05766</td>\n",
       "      <td>...</td>\n",
       "      <td>19.26</td>\n",
       "      <td>99.70</td>\n",
       "      <td>711.2</td>\n",
       "      <td>0.1440</td>\n",
       "      <td>0.1773</td>\n",
       "      <td>0.2390</td>\n",
       "      <td>0.12880</td>\n",
       "      <td>0.2977</td>\n",
       "      <td>0.07259</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>20 rows × 31 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    mean radius  mean texture  mean perimeter  mean area  mean smoothness  \\\n",
       "0         17.99         10.38          122.80     1001.0          0.11840   \n",
       "1         20.57         17.77          132.90     1326.0          0.08474   \n",
       "2         19.69         21.25          130.00     1203.0          0.10960   \n",
       "3         11.42         20.38           77.58      386.1          0.14250   \n",
       "4         20.29         14.34          135.10     1297.0          0.10030   \n",
       "5         12.45         15.70           82.57      477.1          0.12780   \n",
       "6         18.25         19.98          119.60     1040.0          0.09463   \n",
       "7         13.71         20.83           90.20      577.9          0.11890   \n",
       "8         13.00         21.82           87.50      519.8          0.12730   \n",
       "9         12.46         24.04           83.97      475.9          0.11860   \n",
       "10        16.02         23.24          102.70      797.8          0.08206   \n",
       "11        15.78         17.89          103.60      781.0          0.09710   \n",
       "12        19.17         24.80          132.40     1123.0          0.09740   \n",
       "13        15.85         23.95          103.70      782.7          0.08401   \n",
       "14        13.73         22.61           93.60      578.3          0.11310   \n",
       "15        14.54         27.54           96.73      658.8          0.11390   \n",
       "16        14.68         20.13           94.74      684.5          0.09867   \n",
       "17        16.13         20.68          108.10      798.8          0.11700   \n",
       "18        19.81         22.15          130.00     1260.0          0.09831   \n",
       "19        13.54         14.36           87.46      566.3          0.09779   \n",
       "\n",
       "    mean compactness  mean concavity  mean concave points  mean symmetry  \\\n",
       "0            0.27760         0.30010              0.14710         0.2419   \n",
       "1            0.07864         0.08690              0.07017         0.1812   \n",
       "2            0.15990         0.19740              0.12790         0.2069   \n",
       "3            0.28390         0.24140              0.10520         0.2597   \n",
       "4            0.13280         0.19800              0.10430         0.1809   \n",
       "5            0.17000         0.15780              0.08089         0.2087   \n",
       "6            0.10900         0.11270              0.07400         0.1794   \n",
       "7            0.16450         0.09366              0.05985         0.2196   \n",
       "8            0.19320         0.18590              0.09353         0.2350   \n",
       "9            0.23960         0.22730              0.08543         0.2030   \n",
       "10           0.06669         0.03299              0.03323         0.1528   \n",
       "11           0.12920         0.09954              0.06606         0.1842   \n",
       "12           0.24580         0.20650              0.11180         0.2397   \n",
       "13           0.10020         0.09938              0.05364         0.1847   \n",
       "14           0.22930         0.21280              0.08025         0.2069   \n",
       "15           0.15950         0.16390              0.07364         0.2303   \n",
       "16           0.07200         0.07395              0.05259         0.1586   \n",
       "17           0.20220         0.17220              0.10280         0.2164   \n",
       "18           0.10270         0.14790              0.09498         0.1582   \n",
       "19           0.08129         0.06664              0.04781         0.1885   \n",
       "\n",
       "    mean fractal dimension  ...  worst texture  worst perimeter  worst area  \\\n",
       "0                  0.07871  ...          17.33           184.60      2019.0   \n",
       "1                  0.05667  ...          23.41           158.80      1956.0   \n",
       "2                  0.05999  ...          25.53           152.50      1709.0   \n",
       "3                  0.09744  ...          26.50            98.87       567.7   \n",
       "4                  0.05883  ...          16.67           152.20      1575.0   \n",
       "5                  0.07613  ...          23.75           103.40       741.6   \n",
       "6                  0.05742  ...          27.66           153.20      1606.0   \n",
       "7                  0.07451  ...          28.14           110.60       897.0   \n",
       "8                  0.07389  ...          30.73           106.20       739.3   \n",
       "9                  0.08243  ...          40.68            97.65       711.4   \n",
       "10                 0.05697  ...          33.88           123.80      1150.0   \n",
       "11                 0.06082  ...          27.28           136.50      1299.0   \n",
       "12                 0.07800  ...          29.94           151.70      1332.0   \n",
       "13                 0.05338  ...          27.66           112.00       876.5   \n",
       "14                 0.07682  ...          32.01           108.80       697.7   \n",
       "15                 0.07077  ...          37.13           124.10       943.2   \n",
       "16                 0.05922  ...          30.88           123.40      1138.0   \n",
       "17                 0.07356  ...          31.48           136.80      1315.0   \n",
       "18                 0.05395  ...          30.88           186.80      2398.0   \n",
       "19                 0.05766  ...          19.26            99.70       711.2   \n",
       "\n",
       "    worst smoothness  worst compactness  worst concavity  \\\n",
       "0             0.1622             0.6656           0.7119   \n",
       "1             0.1238             0.1866           0.2416   \n",
       "2             0.1444             0.4245           0.4504   \n",
       "3             0.2098             0.8663           0.6869   \n",
       "4             0.1374             0.2050           0.4000   \n",
       "5             0.1791             0.5249           0.5355   \n",
       "6             0.1442             0.2576           0.3784   \n",
       "7             0.1654             0.3682           0.2678   \n",
       "8             0.1703             0.5401           0.5390   \n",
       "9             0.1853             1.0580           1.1050   \n",
       "10            0.1181             0.1551           0.1459   \n",
       "11            0.1396             0.5609           0.3965   \n",
       "12            0.1037             0.3903           0.3639   \n",
       "13            0.1131             0.1924           0.2322   \n",
       "14            0.1651             0.7725           0.6943   \n",
       "15            0.1678             0.6577           0.7026   \n",
       "16            0.1464             0.1871           0.2914   \n",
       "17            0.1789             0.4233           0.4784   \n",
       "18            0.1512             0.3150           0.5372   \n",
       "19            0.1440             0.1773           0.2390   \n",
       "\n",
       "    worst concave points  worst symmetry  worst fractal dimension  target  \n",
       "0                0.26540          0.4601                  0.11890       0  \n",
       "1                0.18600          0.2750                  0.08902       0  \n",
       "2                0.24300          0.3613                  0.08758       0  \n",
       "3                0.25750          0.6638                  0.17300       0  \n",
       "4                0.16250          0.2364                  0.07678       0  \n",
       "5                0.17410          0.3985                  0.12440       0  \n",
       "6                0.19320          0.3063                  0.08368       0  \n",
       "7                0.15560          0.3196                  0.11510       0  \n",
       "8                0.20600          0.4378                  0.10720       0  \n",
       "9                0.22100          0.4366                  0.20750       0  \n",
       "10               0.09975          0.2948                  0.08452       0  \n",
       "11               0.18100          0.3792                  0.10480       0  \n",
       "12               0.17670          0.3176                  0.10230       0  \n",
       "13               0.11190          0.2809                  0.06287       0  \n",
       "14               0.22080          0.3596                  0.14310       0  \n",
       "15               0.17120          0.4218                  0.13410       0  \n",
       "16               0.16090          0.3029                  0.08216       0  \n",
       "17               0.20730          0.3706                  0.11420       0  \n",
       "18               0.23880          0.2768                  0.07615       0  \n",
       "19               0.12880          0.2977                  0.07259       1  \n",
       "\n",
       "[20 rows x 31 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "columns = ['mean radius', 'mean texture', 'mean perimeter', 'mean area',\n",
    "'mean smoothness', 'mean compactness', 'mean concavity',\n",
    "'mean concave points', 'mean symmetry', 'mean fractal dimension',\n",
    "'radius error', 'texture error', 'perimeter error', 'area error',\n",
    "'smoothness error', 'compactness error', 'concavity error',\n",
    "'concave points error', 'symmetry error', 'fractal dimension error',\n",
    "'worst radius', 'worst texture', 'worst perimeter', 'worst area',\n",
    "'worst smoothness', 'worst compactness', 'worst concavity',\n",
    "'worst concave points', 'worst symmetry', 'worst fractal dimension',\n",
    "'target']\n",
    "\n",
    "index=range(0, 569,1)\n",
    "df=pd.DataFrame(data=cancer['data'],index=index,columns=columns[:30])\n",
    "    \n",
    "df['target'] = cancer['target']\n",
    "df.head(20)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### What is the class distribution? (i.e. how many instances of `malignant` (encoded 0) and how many `benign` (encoded 1)?)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "malignant    212\n",
       "benign       357\n",
       "dtype: int64"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mal_count=len(df[df['target']==0])\n",
    "ben_count=len(df[df['target']==1])\n",
    "pd.Series(data=[mal_count,ben_count],index=['malignant', 'benign'])\n",
    "    \n",
    "    \n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   mean radius  mean texture  mean perimeter  mean area  mean smoothness  \\\n",
      "0        17.99         10.38          122.80     1001.0          0.11840   \n",
      "1        20.57         17.77          132.90     1326.0          0.08474   \n",
      "2        19.69         21.25          130.00     1203.0          0.10960   \n",
      "3        11.42         20.38           77.58      386.1          0.14250   \n",
      "4        20.29         14.34          135.10     1297.0          0.10030   \n",
      "\n",
      "   mean compactness  mean concavity  mean concave points  mean symmetry  \\\n",
      "0           0.27760          0.3001              0.14710         0.2419   \n",
      "1           0.07864          0.0869              0.07017         0.1812   \n",
      "2           0.15990          0.1974              0.12790         0.2069   \n",
      "3           0.28390          0.2414              0.10520         0.2597   \n",
      "4           0.13280          0.1980              0.10430         0.1809   \n",
      "\n",
      "   mean fractal dimension  ...  worst radius  worst texture  worst perimeter  \\\n",
      "0                 0.07871  ...         25.38          17.33           184.60   \n",
      "1                 0.05667  ...         24.99          23.41           158.80   \n",
      "2                 0.05999  ...         23.57          25.53           152.50   \n",
      "3                 0.09744  ...         14.91          26.50            98.87   \n",
      "4                 0.05883  ...         22.54          16.67           152.20   \n",
      "\n",
      "   worst area  worst smoothness  worst compactness  worst concavity  \\\n",
      "0      2019.0            0.1622             0.6656           0.7119   \n",
      "1      1956.0            0.1238             0.1866           0.2416   \n",
      "2      1709.0            0.1444             0.4245           0.4504   \n",
      "3       567.7            0.2098             0.8663           0.6869   \n",
      "4      1575.0            0.1374             0.2050           0.4000   \n",
      "\n",
      "   worst concave points  worst symmetry  worst fractal dimension  \n",
      "0                0.2654          0.4601                  0.11890  \n",
      "1                0.1860          0.2750                  0.08902  \n",
      "2                0.2430          0.3613                  0.08758  \n",
      "3                0.2575          0.6638                  0.17300  \n",
      "4                0.1625          0.2364                  0.07678  \n",
      "\n",
      "[5 rows x 30 columns]\n",
      "0    0\n",
      "1    0\n",
      "2    0\n",
      "3    0\n",
      "4    0\n",
      "Name: target, dtype: int32\n"
     ]
    }
   ],
   "source": [
    "X = df.iloc[:,:30]\n",
    "y = df.iloc[:,30:]\n",
    "\n",
    "y = df.target\n",
    "print(X.head())\n",
    "print(y.head())\n",
    "    \n",
    "    \n",
    "    \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Using `train_test_split`, split `X` and `y` into training and test sets `(X_train, X_test, y_train, and y_test)`.\n",
    "\n",
    " \n",
    "* `X_train` *has shape* `(426, 30)`\n",
    "* `X_test` *has shape* `(143, 30)`\n",
    "* `y_train` *has shape* `(426,)`\n",
    "* `y_test` *has shape* `(143,)`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test=train_test_split(X,y,random_state=0)\n",
    "    \n",
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Using KNeighborsClassifier, fit a k-nearest neighbors (knn) classifier with `X_train`, `y_train` and using one nearest neighbor (`n_neighbors = 1`).\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "KNeighborsClassifier(algorithm='auto', leaf_size=30, metric='minkowski',\n",
       "                     metric_params=None, n_jobs=None, n_neighbors=1, p=2,\n",
       "                     weights='uniform')"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.neighbors import KNeighborsClassifier  \n",
    "    \n",
    "    \n",
    "knn=KNeighborsClassifier(n_neighbors = 1)\n",
    "knn.fit(X_train, y_train)\n",
    "    \n",
    "   "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Using knn classifier, predict the class label using the mean value for each feature.\n",
    "\n",
    "using `cancerdf.mean()[:-1].values.reshape(1, -1)` which gets the mean value for each feature, ignores the target column, and reshapes the data from 1 dimension to 2 (necessary for the precict method of KNeighborsClassifier).\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1])"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "means = df.mean()[:-1].values.reshape(1, -1)\n",
    "    \n",
    "\n",
    "prediction = np.array(knn.predict(means))\n",
    "prediction\n",
    "    \n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Using your knn classifier, predict the class labels for the test set `X_test`.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(143,)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prediction = np.array(knn.predict(X_test))\n",
    "prediction.shape    \n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Find the score (mean accuracy) of your knn classifier using `X_test` and `y_test`.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.916083916083916"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "knn.score(X_test,y_test)\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Visualization\n",
    "\n",
    "Using the plotting function below to visualize the differet predicition scores between training and test sets, as well as malignant and benign cells."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def accuracy_plot(): \n",
    "\n",
    "   \n",
    "\n",
    "    # Find the training and testing accuracies by target value (i.e. malignant, benign)\n",
    "    mal_train_X = X_train[y_train==0]\n",
    "    mal_train_y = y_train[y_train==0]\n",
    "    ben_train_X = X_train[y_train==1]\n",
    "    ben_train_y = y_train[y_train==1]\n",
    "\n",
    "    mal_test_X = X_test[y_test==0]\n",
    "    mal_test_y = y_test[y_test==0]\n",
    "    ben_test_X = X_test[y_test==1]\n",
    "    ben_test_y = y_test[y_test==1]\n",
    "\n",
    "   \n",
    "\n",
    "    scores = [knn.score(mal_train_X, mal_train_y), knn.score(ben_train_X, ben_train_y), \n",
    "              knn.score(mal_test_X, mal_test_y), knn.score(ben_test_X, ben_test_y)]\n",
    "\n",
    "\n",
    "    plt.figure()\n",
    "\n",
    "    # Plot the scores as a bar chart\n",
    "    bars = plt.bar(np.arange(4), scores, color=['#4c72b0','#4c72b0','#55a868','#55a868'])\n",
    "\n",
    "    # directly label the score onto the bars\n",
    "    for bar in bars:\n",
    "        height = bar.get_height()\n",
    "        plt.gca().text(bar.get_x() + bar.get_width()/2, height*.90, '{0:.{1}f}'.format(height, 2), \n",
    "                     ha='center', color='w', fontsize=11)\n",
    "\n",
    "    # remove all the ticks (both axes), and tick labels on the Y axis\n",
    "    plt.tick_params(top='off', bottom='off', left='off', right='off', labelleft='off', labelbottom='on')\n",
    "\n",
    "    # remove the frame of the chart\n",
    "    for spine in plt.gca().spines.values():\n",
    "        spine.set_visible(False)\n",
    "\n",
    "    plt.xticks([0,1,2,3], ['Malignant\\nTraining', 'Benign\\nTraining', 'Malignant\\nTest', 'Benign\\nTest'], alpha=0.8);\n",
    "    plt.title('Training and Test Accuracies for Malignant and Benign Cells', alpha=0.8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYIAAAEUCAYAAAAmxTHXAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4xLjAsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy+17YcXAAAgAElEQVR4nO3de7xUVd3H8c8XkLsKKqhxScorpqmRmmZpeUEzMSsTM7XM41Naj5kWPZWa9pSpPfVY3jDTtLyVplgk3kEzFUwzwfQhUkTygoCiIBf5PX+sdXAY5pyZw5lzY3/fr9d5ndl7r1l7zZq192+vtS+jiMDMzIqrW0cXwMzMOpYDgZlZwTkQmJkVnAOBmVnBORCYmRWcA4GZWcF1ukAgqZuk+yRtVs+0HUnSMEnTOroc6xJJe0j6dRvke5SkO3O76lnv/NeGpHdLeqBk+jJJH+nIMrU3SX0lTZO0cQes+8uSvt7e661G0l6SbiyZvkvSDmuTV486FOa+ksnewHLgrTz9g4j4U0vyi4iVwF71TtsZSeoGTC6ZVV5/Z0fE7WuZ99XA1dXeL2kDYBIwOSLGrc26OkJEPAA8UDVhC0jqC3wF+GREzKlTnncBvYD9I2JxyfybgOHAvhGxsCV5RsTx9Shba+S6mgIcEBGvdILyXA28m7TtrASeBH4YEc+2Nu+IuKi1eTQl7wOOAg4BNgNeAx4FLouIZ9pqveVaHQgiYtWOWNKtpJ3Xw02ll9Q9It5qanmRlAcySROB70bEI+1YjNHAEuBDkjaIiNfaa8WdsC0MBt5amyCQN+iIyndovgTsC0zIaXdsVSmtKWdGxO2SepAC+unAcR1cpmq+A7wX+D7wBGmfvB+wB/BMexWizYeGcrfqh5J+IGkKcJCkHSVdKeleSZMknZa/PCR1z13Ad+Tps/PyCyRNkXRFybKa0+ble0i6SdJkSd+Q9EtJH2+i3LWU8TBJN0u6R9JpJe/tJukUSXdLugX4QCvqr7ukBkkTctfvLEn98rK+ks7J67knl7d/7sZuA5yZhzi+2swqDgauBl4gNcDSdQ+R9JO83jsb81HymVyXUyRdJ+ldlbrvks6VdGx+vZekGyWdIOkO4BuSNpL0s7yOuyWdL2mjkvdvJOn7km7Py/+7NK+SdJuXlPUWSZ8oWbazpGtyWSdJ+nKFet4G+A3QM9fZT/L8Ufm9k3N72q7kPVfn7+Yq4H5go/J8sz8CHyur8z+Urf8juR6nSPqDpGOayKtxvfvn1z0kfTPXzc2Sxmr1YaSrJX1R0lU5759K6p+XrSfpvFy390q6WNLwkveem9vxRfm9l0vaNC++LP+/JdfXGj3z3CYuy2W7Q9IZSj2JxuV35fL+NtfvWcrbWF5+fH7fROCApuqjXESsAG4HRpTk1dx29G5JD0g6VNKf8jqPLHnvyZL+q2T6MEkTc7qjVDIkk9OepbTPmyLpWklbViqnpK1JbeEbEfFoRCyPiCURMSEirslpeivtqybmtnuqpPWq1UEtbb5Ue50j2Ae4Ddib9AWtAM4HPgp8gbSjPKyZ948GLgE+QtphfamlafPO5Rzgf/N6nwe2byafWsr4QVK37rPAgZJ2zfM/BewOHAEcTdkOtoWOBUYBnwcOyvO+lv8fBgTpM+8LnAcsj4gfA0+RjpD2iogLKmUsaQSwHWlo6DZKdla5sf0M+L88/2Dg3rz44/kzjwM+nP+/XuPnGZbLfBDwP6Q2+FvgQGAM6YjoayXpzyENlx1G2hncSBlJ3YELgEdymv8Ejpe0U04yjtTV/lDOZ3J5HhHxFOm7Wpbr7GuSNsll/AWpPd0C/G/pzix/ju/keljQxGeeCgyRtJnSeYe9SdtBqTeAb+Vl3wCOLWlPzRlLOqL8NKmNVGpro0l1MBoYCHwmzxdwD3Aoqd7mAGdUeO9PSdvBAqAhz28cnhqT6+s+KrsE2D+X892k9lzqIznPTwA75bRI+miedxxpe/pgE/mvIdfxaNIRdqNjaXo7AlgP2IrUBk8Bvipp8wp5jwS+CpxK2i6GAOtX+Ew3kb7LR3N+lewGPBMR/2zm45xG+s4OJ9XDu4DPNZO+UdU2X6q9AsFjETElIlZGxNKImBERT0TEWxHxPPB74H3NvP+u/J4VwJ9IR7stTftB4OmImJyXXQM0OTZbYxmviIjXI2IuaSfUuK79gGsi4qWIeBW4spnyVvNJ4IKIeCUilpJ2SvvnZStIjWRoLuf0nKZWBwOP5/L/Cdix5IhwF6AncElEvJn/Hs/LDgUuj4inI3kmIl6qcZ1v5vcuz21hXm4byyJiEamu3geQy/Ie4Nxcz8sj4q8V8nwfoIj4dUSsyGOrf2D1ehquNPT1RkRMr7GsewMzIuLuXL83k3aGpT28myJidi7byibyCVKwPYg0FPg48OpqCSIeioh/5W1kBnA3zW8TjfYjnQt6JSIWAFdVSHNTRMzN5yjuIrfTXOcTI2JxbjeXATuUHXFOyt/z8vwZtq6hTI2faVZEPJK/k3nAdaR2Veo3EbEgIuaTzvk05r8fcGOu28W83QNpzumS7iWdu/gYaVtp1Nx2BCkoXpLr5O/Ac0ClI/l9gTvz/mEZcDFr7kcfioipuT38kab3VxsC85r6MPl7OBg4P7f/RcCvqK131KI23+pzBDV6sXRC0hakaLwd6QRpd1aP3uVKK+tNoM9apB1UWo6ICEmrlWstylh6kqzJdQH/bqa8TVIadx4EXCipdOy5h6T1SUcdGwHnS+pN2vld0swOqTzvA4FfAkTEc5JmkBreRcCmwNwm8tqUdPS4NuaVnhfI3fNTSUdH/Rs/X8l6XomIJVXy3AwYlncCjboBf8mvvwucABwjaTZwcUQ8VENZB7Hmd/dv0rmERk22oTJ/JPXYngVuLV8oaRdS7/VdpM+/XqV0FWxSVoZK5am4TeRhmK+SAt4A0knWbqQj3Pk5fXkbL+0NNUvSYNJ3u2N+nyqUr6n8B5GG2xrVsg2dlc8RdCMd/V8g6WhSW21uO4LUE1xUVpZK+5lBwOzGiYh4TdLisjRN7RfKvUr6/poymLTfuVFS4zwBtRzstajNt1cgKD+B9l+kneq3ImKxpM/R9lf/zCMN1wBpnJvVN+hyrSnjPNJOrNFaXd4aESslzQP+MyKebiLZRcBFkoYBFwIzScMO1R4ruyvp839ZUmN3vx+wkaSLSRvsOyQpYo0ToC8CQ0m9oFJvknYmvUvmlV/uV57XcTnNURExPw/nNF6l8SKwsaTeEfFmM5/lReCfEXFkpYURMQv4Zt5BHAScJ2mfqH6i+mXSsEupzUgnf5v6PBVFxKy8w9gR+Car1xGkIbBLgD9ExDJJ3yVt9NXMY/V2vGlTCSs4lLTDPD4iXsw77ok1rreWz/010pDhpyNikaSDqP3k7VpvQ/ng5eG87bw/ImY3tx3lz12r1eo7B5Kag2OZh4CvSHpXbqPlXiZtTx8vC1JVtbTNd9R9BP1IDWRJHqdu7vxAvdwHbCvpQ3lMeSxpWKUtyngHcKSkwZI2ZM1x0Za4kdRYBsOqk6d75de7SRqRv+w3SN3Bxi96Pmln3ZTGMf9Pk+qi8W8j0pDEX4FlwAmSeuWTVo1Xu9wMfEHSVkq2kDQ4b4D/JJ0v6SZpH5o/DwNpI3oTWCRpIOl8DAARMZsUjL8hqZ/Syc2dK+TxV2A9SYdL6ql0YnDrfDIOSR/LXeSVpO80qG1HNhkYKWnvnOchpKD1YA3vreTbwJfzMMsq+fvrQxqqXJ6DYa33CdwJHJXbxQDSOata9SUdXS7K5z2aPaFYKvfSFpPGyJvSj9Qu31C6aKNioG7CHcBhkobnsn2x1jfmNvm+XLbGHWyT21EL3QHsJ2m7fC7iS6SddYvloPRH4EeS3qt04r+3pIMkHZmHnv4AnCppw/y5Nqvl3FFL23xHBYKfkHZEU0hH3ne09QrzGOS3SEcpd5N2kk+Rdnb1LuPvgIdJY6JXkzbWtXUF6YTTeKWrri7n7THHTXM5pwDXknZc9+RlvwbGKF0NclJphnk4Zh/gujxm2vg3O5f14Lyz+iowknT+4FbSCVHy6+uBc/M6f0ja6AF+RDoCuRfYE/hzlc93Fal7fDdpHPj+suXjSEfPt5DGqD9RtpySso4ibTh3kI66G4/UPgz8PtffCaReXtWNNyJeJg1tNOTyfZJ0VPlGtfc2kd/sSkekuSw/zOuaTDoRf1eN2V4LTCe1uStJbWF5c28o8XtgEaleryMF1Ja4hDQsea+kSidzLyJ9J5NJ7aIl28FdpMttLyd9tlruGTlT6b6mKaSge35EPJqXNbcd1Syfv/k58GNS72ku6fLrpvYj1ZxN2p5OJ20zN5EuHW3cDs4lnZf6NakeL6D5A7xGLWrzWrPXXwz5KOw24JsljcWsS5O0L9AQEYd3dFmKIPfC7gT2yyfru6RO94iJtqR0H0H/3KX7ImkYpdYrSMw6ndyed81DcZuThtbu7eBirdMkfTgPl/YlXRr6t64cBKD9ThZ3FjuR7uDrQRo7/HoehzPrqroBJ5Puz1hCCgJXdGSBCmB/4CzSmPvfSVfodGmFHRpqDUkNETG+o8vRVbn+Ws912Dquv9UVamiojhqqJ7FmuP5az3XYOq6/Eg4EZmYF15HnCLrsmNSll14KXbj8Hc3113quw9bp4vVXyw1/LcuwA88RdNUvwcysI9U9EHhoyMys4BwIzMwKzoHAzKzgHAjMzArOgcDMrOCqBgKl3/V9SVLFH47Jj0a9QNJMSY8r/cCGmZl1EbX0CK4k/f5nUw4k/dbnVqS79S5ufbHMzKy9VA0EETGFt3+2rpIxwFWRPAgMUIUffTYzs86pHncWDyH90HOjOXneGr8xqvSTiA2Q7uxraFi7x318/Ou3rNX71hW3/nhMq97v+mtd/Zl1pNL9aDa+tQ/Qq0cgqHSXW8W7hnNhxzeXxszMmla2H62Lelw1NIf0LPRGQ0k/32ZmZl1APQLBBODofPXQ7sCrEbHGsJCZmXVOVYeGJF0L7A1sImkOcAawHkBEXEL6AeeDgJnAYuDzbVVYMzOrv6qBICLGVlkewIl1K5GZmbUr31lsZlZwDgRmZgXnQGBmVnAOBGZmBedAYGZWcA4EZmYFV49HTJiZtcjh13+po4vQoW74TOd6SLMDQfaFj2/PHjtszqYb9+PE8+5m9guL1kjTTdDwiR3ZZZvBBMGNd/8ftz80u+qyInD9mXVdHhrKHnzi34y76H5enL+4yTQf3mUYm2/SjxPOuZPTLriPsftvy+CBfaouKwLXn1nX5UCQzfjXfOYtfLPZNHvt9A4mPfgMEfDaG8t48Il/s+d7h1RdVgSuP7Ouy4GgBQYN7MvLC5asmn554RIGDehTdZklrj+zzsmBwMys4BwIWuDlBYsZVDJuPWhAH15euKTqMktcf2adkwNBC/z58bkcsPsWSLBBv57s/p7NeeDxuVWXWeL6M+ucfPlo1nDoDnxgh80ZuH4vvn/CHixavIwTz7uHM764O7+57R/MnLOQe6Y9x9bDB3LpuH0BuO6Op1ZdJdPcsiJw/Zl1XUo/J9Ah1nrF/vF1/3h9a/jH6zuebyhr1Q1llX4nvlU8NGRmVnAOBGZmBedzBGa2Tti8/2BO3O0Y+vfqx+tL3+DnD13JC6+/vFqaDXtvQMOoIxncb2O6d+vO72fcxn3PPrx6Putvyrn7/xe3z5zM1X+7qT0/Qodxj8DM1gnHjzqSSTMnc/LEM5k0czINoz67RppjdvoUs+Y/y2mT/psz7v4fxu4who37DFy1XBINo45k6vN/a8+idzgHAjPr8jbotT4jBg7j/tlTAbh/9lRGDBzG+r36r5bunQOG8NgLMwBYtPR1nlk4hw8M32XV8kO3PYC/zv07/170YvsVvhPw0JBZCxX9ihfofI9R3rjvQOYvWUjjVZARwYIlr7JJ34EsWvr6qnSzFsxmj+Gj+Of8ZxnUb2O23uRdvPzGKwAM33AI791sJN+79yd8auRBHfI5Oop7BGZWGFc9diMDeq3PuQd8my/sfDjTX3yKFfEW3dWNE97/WS575Bo68JL6DuMegZl1ea8sXsBGfQYgiYhAEgP7bMi8xQtWS7do6ev87KErV02P2+tEnn/tBQb02ZBN+w/iWx86CYB+6/VBiD7r9Wb8tGva86N0CAcCM+vyXlu6iGcWzuGDw9/Pfc8+zAeHv59/LXhutWEhgP49+7F4+RJWxkq2H7wNwwe8g/95YDzL3lrOF28+bVW6T2//MXr36FWYq4YcCMxsnXDZtGs4cbdj+OT2B/HGssX8/KFfAemo/4YnbmXWgtlsudEWfH6Xw1kZK1m09HV+dN/FLHtreQeXvOM5EJjZOmHuohf59p3nrjH/nPsuXPX6sRem858Tz6ia12+n/7GuZevsfLLYzKzgHAjMzArOgcDMrOAcCMzMCs6BwMys4Gq6akjSaOB/ge7ALyLinLLlw4FfAQNymnERMbHOZTVbp9Xy9MwNeq3Pl3f9HBv3HUiPbj144qWnuOKvN7AyVnLibsfwzg2HrEo7fMAQzrv/Uh6Z+3h7fxTrYqoGAkndgQuB/YA5wFRJEyJiRkmy7wA3RMTFkkYCE4Et2qC8Zuusxqdn3vfsw+z1zl1pGPVZzrr3p6ul+cTI0Tz/2gucc99FdFc3zvroqew2dCf+8txfuTBfNw/p4Wqn730yf3thRvlqzNZQy9DQrsDMiJgVEcuA64Dy3/oLYIP8ekPAvzpu1gK1Pj2TCHqv1xshenRfjx7dejB/ycI18vvIiD25/9mprFi5oj2Kb11cLYFgCPBcyfScPK/UmcBRkuaQegNfqUvpzAqiuadnlvrdjIls3n8wl445h8sOOYe/vTCDp+bNWi1N927d2fOd7+fufz3QbuW3rq2WQFDph5LLH883FrgyIoYCBwFXS1ojb0kNkqZJmjZ+/PiWl9as4D4wbBdmv/o8J9wyjhNu/RbbDdqS3YbuvFqaXYe8l3mL5/PswjkdVEprS6X70fzX0No8azlZPAcYVjI9lDWHfo4DRgNExF8k9QY2AV4qTRQR44HGCFC8Z72aNaHWp2eO3mofLn74KoJgyfI3mfb847xn8DY8NOfRVWn2GbEH98xyb2BdVbYfrYtaegRTga0kjZDUEzgCmFCWZjbwUQBJ2wG9gZcxs5qUPj0TaPLpmS+/Po+dNtseSENAO2y6LbNfffu4bKM+A9h20JarzjWY1aJqjyAiVkg6CZhEujT0lxExXdJZwLSImAB8HbhM0tdIR/rHRhF/3cGsFWp5euaVj/6W40cdyfkHfIdu6sb0l57mrln3r8rjw1vsziNz/84byxZ31MewLqim+wjyPQETy+adXvJ6BrBnfYtmViy1PD3zxTfm8f3JFzSZx++fvK1NymbrNt9ZbGZWcA4EZmYF50BgZlZwDgRmZgXnQGBmVnAOBGZmBedAYGZWcA4EZmYF50BgZlZwDgRmZgXnQGBmVnAOBGZmBedAYGZWcA4EZmYF50BgZlZwDgRmZgXnQGBmVnAOBGZmBedAYGZWcA4EZmYF50BgZlZwDgRmZgXnQGBmVnAOBGZmBedAYGZWcA4EZmYF50BgZlZwDgRmZgXnQGBmVnAOBGZmBedAYGZWcA4EZmYFV1MgkDRa0lOSZkoa10SawyXNkDRd0jX1LaaZmbWVHtUSSOoOXAjsB8wBpkqaEBEzStJsBXwL2DMiFkga3FYFNjOz+qqlR7ArMDMiZkXEMuA6YExZmuOBCyNiAUBEvFTfYpqZWVupJRAMAZ4rmZ6T55XaGtha0p8lPShpdL0KaGZmbauWQKAK86JsugewFbA3MBb4haQBa2QkNUiaJmna+PHjW1pWM7PCK92P5r+G1uZZ9RwBqQcwrGR6KDC3QpoHI2I58C9JT5ECw9TSRBExHmiMAOXBxMzMqijbj9ZFLT2CqcBWkkZI6gkcAUwoS3MzsA+ApE1IQ0Wz6llQMzNrG1UDQUSsAE4CJgFPAjdExHRJZ0k6JCebBLwiaQZwD3BaRLzSVoU2M7P6qWVoiIiYCEwsm3d6yesATsl/ZmbWhfjOYjOzgnMgMDMrOAcCM7OCcyAwMys4BwIzs4JzIDAzKzgHAjOzgnMgMDMrOAcCM7OCcyAwMys4BwIzs4JzIDAzKzgHAjOzgnMgMDMrOAcCM7OCcyAwMys4BwIzs4JzIDAzKzgHAjOzgnMgMDMrOAcCM7OCcyAwMys4BwIzs4JzIDAzKzgHAjOzgnMgMDMrOAcCM7OCcyAwMys4BwIzs4JzIDAzKzgHAjOzgnMgMDMrOAcCM7OCqykQSBot6SlJMyWNaybdpySFpFH1K6KZmbWlqoFAUnfgQuBAYCQwVtLICunWB74KPFTvQpqZWduppUewKzAzImZFxDLgOmBMhXRnA+cCb9axfGZm1sZqCQRDgOdKpufkeatI2hkYFhF/aC4jSQ2SpkmaNn78+BYX1sys6Er3o/mvobV59qhlvRXmRUmhugE/AY6tllFEjAcaI0A0l9bMzNZUth+ti1p6BHOAYSXTQ4G5JdPrA+8B7pX0DLA7MMEnjM3MuoZaAsFUYCtJIyT1BI4AJjQujIhXI2KTiNgiIrYAHgQOiYhpbVJiMzOrq6qBICJWACcBk4AngRsiYrqksyQd0tYFNDOztlXLOQIiYiIwsWze6U2k3bv1xTIzs/biO4vNzArOgcDMrOAcCMzMCs6BwMys4BwIzMwKzoHAzKzgHAjMzArOgcDMrOAcCMzMCs6BwMys4BwIzMwKzoHAzKzgHAjMzArOgcDMrOAcCMzMCs6BwMys4BwIzMwKzoHAzKzgHAjMzArOgcDMrOAcCMzMCs6BwMys4BwIzMwKzoHAzKzgHAjMzArOgcDMrOAcCMzMCs6BwMys4BwIzMwKzoHAzKzgHAjMzArOgcDMrOBqCgSSRkt6StJMSeMqLD9F0gxJj0u6S9I7619UMzNrC1UDgaTuwIXAgcBIYKykkWXJHgVGRcSOwO+Ac+tdUDMzaxu19Ah2BWZGxKyIWAZcB4wpTRAR90TE4jz5IDC0vsU0M7O2UksgGAI8VzI9J89rynHAn1pTKDMzaz+1BAJVmBcVE0pHAaOA85pY3iBpmqRp48ePr72UZmYGrL4fzX8Nrc2zRw1p5gDDSqaHAnMrFG5f4NvAhyNiaaWMImI80BgBKgYTMzNrWtl+tC5q6RFMBbaSNEJST+AIYEJpAkk7A5cCh0TES/UsoJmZta2qgSAiVgAnAZOAJ4EbImK6pLMkHZKTnQf0B34r6TFJE5rIzszMOplahoaIiInAxLJ5p5e83rfO5TIzs3biO4vNzArOgcDMrOAcCMzMCs6BwMys4BwIzMwKzoHAzKzgHAjMzArOgcDMrOAcCMzMCs6BwMys4BwIzMwKzoHAzKzgHAjMzArOgcDMrOAcCMzMCs6BwMys4BwIzMwKzoHAzKzgHAjMzArOgcDMrOAcCMzMCs6BwMys4BwIzMwKzoHAzKzgHAjMzArOgcDMrOAcCMzMCs6BwMys4BwIzMwKzoHAzKzgHAjMzArOgcDMrOAcCMzMCq6mQCBptKSnJM2UNK7C8l6Srs/LH5K0Rb0LamZmbaNqIJDUHbgQOBAYCYyVNLIs2XHAgojYEvgJ8KN6F9TMzNpGLT2CXYGZETErIpYB1wFjytKMAX6VX/8O+Kgk1a+YZmbWVhQRzSeQPgWMjogv5unPAbtFxEklaZ7Iaebk6X/mNPPK8moAGvLk+IgYX7dP0o4kNXTVsncGrr/Wcx22Tleuv7L9KNRhX1pLj6DSkX159KglDRExPiJG5b8u+SVkDdWTWDNcf63nOmydLlt/ZfvRuuxLawkEc4BhJdNDgblNpZHUA9gQmN/awpmZWdurJRBMBbaSNEJST+AIYEJZmgnAMfn1p4C7o9qYk5mZdQo9qiWIiBWSTgImAd2BX0bEdElnAdMiYgJwOXC1pJmknsARbVnoTqArD2t1Bq6/1nMdto7rr0TVk8VmZrZu853FZmYF50BgZlZw62wgkDQtn8donO4u6U5JP63yvvc1ppH0IUnHtnFRS9e9taQ922t9a0vSw5KukXStpN9I2rEVef2HpF3rWb7OwO2v7bj91V/Vk8Vd2BJgS0m9ImIpsBvwUksyiIgpwJS2KFwTtgG2A/7cjutcG0sj4kgASR8ATmItr8uOiEvqWbBOxO2v7bj91dm6HAggNegPAncBo0lXPu0MIGl74OtAb+BN4HsR8WzpmyV9HNguIs6VNBT4PqkX9QDw2YjYS9L7gBOAhcC7gSeB70ZESDoe2Cuv42/AD/L88cATwCigP3B2nv4PoJeknYArI+L2NqqXeuoHLGqckHQ0sC/QE7gnIi6V9A7gAuAxYEfgZeCUiFgq6Uzgvoi4Kx+NnkKqy38AQyLi5Hwn5Wake1g2A66JiOva7ROuPbe/tuf2Vwfr7NBQdjtwQL7/YUtSY2/0DHB8PrK4BDixSl6nAtdGxNGkhlRqG+B84NPAEOC9ef71EXF0RBwO9CJtlI2657x+nMuxPJfj9og4spNvhL1y1/xG4LvALwAk7U66sfAY4EhgO0m75PcMB27IdbEI+Ghphvk7+jbwlYg4DhhYts4tSEd+RwMN+cbFzs7tr224/dXZOvVhykXE/0nanHQ0Vt7d7Q98T9Jw0uMwqtXFjqQjOIDbgJNLlk2PiJcAJD0NvIN09DFK0jGkI7INgFm83dW/O/9/MqfvSkq75juS6vEzwO757zc5XV/ShvkC8HxEPJ3nPwlsXpbnFsCciGi8a/024LCS5ffnhx4ukzQf2IgWDrW0N7e/NuP2V2frdCDIppA2mgbSoy8afYl0Q9ypuet4aSvWsazk9VtA93yEMQ74XES8mLuXPUvSLc//V5Ju1OuSIuJxSQNIR1ACroiIm0rT5PpdXjKr0meu9rTa8vd3lbbr9teG3P7qY10fGgK4BbgsImaWze/P2xH94Bry+TtvdycPqCF9r/x/oaS+pHHLat4gjXl2GUo/QtSdNK76F2BM/rxIGixpoxqzegYYmjdagP3rW9IO4/bXhtz+6mOdimqV5C7ztRUWXQWcKeko0vOUqvkxcHZOfz/wepX1LpJ0M3A96SF902tYxwb0n2AAAANaSURBVDTgWEnX0LlP1vXKZYR0JHVGRKwEHpQ0ArhC6ecoFpPGcFdWyzCfuDsH+JmkhdRWX52e21+bcPurMz9iokaSepPGJkPS/qTfXzilo8u1LpHUNyIWK23F3wRmR8Q11d5XBG5/ba/I7W+d7xHU0XbAN3IjWQScVSW9tdyhkg4G1gOeAm6qkr5I3P7aXmHbn3sEZmYFV4gegaQNgYvz5CakKysW5Olj8jXU1fI4gzRu+mwzaQ4HFkXEn1pZ5E7F9dc+6lHPOZ9DgD9HxCv1L2Xn5fpbe4XrEeTL6JZExNVl80Wqj6onlorM9dc+mqrnGt97OfCjkuvmC8f11zKF6BE0RdIw0tUYjwHvAU7Ot+VvS7r87o6IuCynvRz4EfBP0iMDbgT2ID0e4OsRMV/Sl4GFEXFNTv8Y8H7SpYJn5mue+wDfI93o8q/8/+yu2Ohcf+0nj10fTtpmHwfOJV8xQ7qzWKQx7fnA1sA5kt6kBUfC6zLXX/OKcB9BNSOAm/Nt9S8BP4uIzwFjgd0kvavCe/oDj0TEWNL13Yc0kbfybfw/BY7P8z4DvJLfeyWpEXZlrr82JundwD7A5/Mdtd1J17lvBwyIiM/kRyf8MV/y+TQwLn8n6/xOrBrXX3WF7hFkcyJiRsn0aEljSI1lEGlHN6vsPUsj4oH8+knyg8QqaLyN/x+8fRv/TsCvACLiaUnleXc1rr+2txswkvRzsJAeGfEi6QaqLSSdSnqExYMdVsLOzfVXhQNBelwwAPm5L0eQuoOLJJ3N23dolio9SniLpm/RX1YhTbVb2bsa11/7mBARF5fPlHQEaYjtCOAjwH+3d8G6CNdfMzw0tLp+pLsR35C0CfCBNljHY8B+AJK2BCoNnXRVrr+28TCwX36mDpI2lLSZpIEAEXEn6VlF2+b0Xe5REW3M9VeFewSr+wdpGON64HnSM9zr7XrS0xKvy+ubSZXHBXQhrr82EBEzlX5D4CJJ3YAVwA9Ij044PQ93QHrmPsCtwHeLdLKzOa6/6gp3+WhHk9Sd9Cz4ZXko5efAJyLirQ4uWpfg+jOrP/cI2l9f4OK8QxPpV6O8E6ud68+sztwjMDMrOJ8sNjMrOAcCM7OCcyAwMys4BwIzs4JzIDAzKzgHAjOzgvt/2dSKdjGExp0AAAAASUVORK5CYII=\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "accuracy_plot() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "coursera": {
   "course_slug": "python-machine-learning",
   "graded_item_id": "f9SY5",
   "launcher_item_id": "oxndk",
   "part_id": "mh1Vo"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
